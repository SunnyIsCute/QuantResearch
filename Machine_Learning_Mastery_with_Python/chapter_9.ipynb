{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Chapter 9 Evaluate the Performance of Machine Learning Algorithms with Resampling\n",
        "\n"
      ],
      "metadata": {
        "id": "SB1qetxOVYJa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, KFold, cross_val_score, LeaveOneOut, ShuffleSplit\n",
        "from sklearn.linear_model import LogisticRegression"
      ],
      "metadata": {
        "id": "xTiKBFGwWgRa"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Split into Train and Test Sets"
      ],
      "metadata": {
        "id": "e4PxDseOWgmw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h2LEkQGGVI_C",
        "outputId": "9204a9e8-551f-42ef-fb14-eee2f042005f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 78.740%\n"
          ]
        }
      ],
      "source": [
        "# evaluate using a train and a test set\n",
        "filename = 'data/pima-indians-diabetes.data.csv'\n",
        "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
        "df = pd.read_csv(filename, names=names)\n",
        "array = df.values\n",
        "X = array[:,:-1]\n",
        "Y = array[:,-1]\n",
        "test_size = 0.33\n",
        "seed = 7\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=test_size, random_state=seed)\n",
        "model = LogisticRegression(max_iter=200)\n",
        "model.fit(X_train, Y_train)\n",
        "result = model.score(X_test, Y_test)\n",
        "print(f'Accuracy: {result*100:.3f}%')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. k-fold Cross Validation\n",
        "\n",
        "Cross validation is an approach that you can use to estimate the performance of a machine learning algorithm with less variance than a single train-test set split.\n",
        "\n",
        "It works by splitting the dataset into k-parts (e.g. k = 5 or k = 10). Each split of the data is called a fold. The algorithm is trained on k− 1 folds with one held back and tested on the held back fold. This is repeated so that each fold of the dataset is given a chance to be the held back test set. After\n",
        "running cross validation you end up with k diﬀerent performance scores that you can summarize using a mean and a standard deviation."
      ],
      "metadata": {
        "id": "pDS6J1T6WDLm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate using cross validation\n",
        "num_folds = 10\n",
        "seed = 7\n",
        "kfold = KFold(n_splits=num_folds, shuffle=True, random_state=seed)\n",
        "model = LogisticRegression(max_iter=200)\n",
        "results = cross_val_score(model, X, Y, cv=kfold)\n",
        "print(f'Accuracy: mean: {results.mean()*100.0:.3f}%, std: {results.std()*100.0:.3f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OqJVErnfWE-f",
        "outputId": "00c82dae-5f34-46eb-8be0-21b646b650f6"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: mean: 77.216%, std: 4.968%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. Leave One Out Cross Validation\n",
        "\n",
        "You can configure cross validation so that the size of the fold is 1 (k is set to the number of observations in your dataset). This variation of cross validation is called leave-one-out cross validation. The result is a large number of performance measures that can be summarized in an eﬀort to give a more reasonable estimate of the accuracy of your model on unseen data.\n",
        "A downside is that it can be a computationally more expensive procedure than k-fold cross validation."
      ],
      "metadata": {
        "id": "AySUusm8WFZh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate using leave-one-out cross validation\n",
        "loocv = LeaveOneOut()\n",
        "model = LogisticRegression(max_iter=300)\n",
        "results = cross_val_score(model, X, Y, cv=loocv)\n",
        "print(f'Accuracy: mean: {results.mean()*100.0:.3f}%, std: {results.std()*100.0:.3f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fr0y-kmFWHVp",
        "outputId": "d1259f35-4d59-42aa-8602-559aced15ec5"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: mean: 77.604%, std: 41.689%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can see in the standard deviation that the score has more variance than the k-fold cross validation results described above."
      ],
      "metadata": {
        "id": "hPOZFRvhaBCv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4. Repeated Random Test-Train Splits\n",
        "\n",
        "Another variation on k-fold cross validation is to create a random split of the data like the train/test split described above, but repeat the process of splitting and evaluation of the algorithm multiple times, like cross validation. This has the speed of using a train/test split and\n",
        "the reduction in variance in the estimated performance of k-fold cross validation. You can also repeat the process many more times as needed to improve the accuracy. A down side is that repetitions may include much of the same data in the train or the test split from run to run, introducing redundancy into the evaluation."
      ],
      "metadata": {
        "id": "IpwCJFwLWHz8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate using shuffle split cross validation\n",
        "n_splits = 10\n",
        "test_size = 0.33\n",
        "seed = 7\n",
        "kfold = ShuffleSplit(n_splits=n_splits, test_size=test_size, random_state=seed)\n",
        "model = LogisticRegression(max_iter=200)\n",
        "results = cross_val_score(model, X, Y, cv=kfold)\n",
        "print(f'Accuracy: mean: {results.mean()*100.0:.3f}%, std: {results.std()*100.0:.3f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qv2advqjWKa2",
        "outputId": "34ab0d9b-4c25-41d7-85cf-96dd54613510"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: mean: 76.535%, std: 2.235%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see that in this case the distribution of the performance measure is on par with k-fold cross validation above."
      ],
      "metadata": {
        "id": "XXLcfdX9a-zc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What Techniqes to Use When\n",
        "\n",
        "- Generally *k-fold cross validation is the gold standard* for evaluating the performance of a machine learning algorithm on unseen data with k set to 3, 5, or 10.\n",
        "- Using a train/test split is good for speed when using a slow algorithm and produces performance estimates with lower bias when using large datasets.\n",
        "- Techniques like leave-one-out cross validation and repeated random splits can be useful intermediates when trying to balance variance in the estimated performance, model training speed and dataset size.\n",
        "\n",
        "The best advice is to experiment and find a technique for your problem that is fast and produces reasonable estimates of performance that you can use to make decisions. If in doubt, use 10-fold cross validation."
      ],
      "metadata": {
        "id": "AWqY3wD5bCh2"
      }
    }
  ]
}